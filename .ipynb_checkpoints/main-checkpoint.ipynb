{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.init_params import N_ELECTRODES, MATERIAL_ORDER, batch_size, N_PEAKS\n",
    "from src.represent_cv_sample import DataSample\n",
    "from src.represent_tea_sample import CompoundDataSample, DataEncodeMode\n",
    "from src.represent_ms_sample import MSDataSample\n",
    "from src.preprocess_data import split_dataset, make_data, aug\n",
    "from src.metrics import calc_metrics\n",
    "from src.FCN import FCN_Model, train, plot_history, evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, namedtuple\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect CV data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datadir = Path(\"CV\")\n",
    "data: Dict[Tuple[int], DataSample] = defaultdict(list)\n",
    "    \n",
    "for sample_file in train_datadir.glob('*.txt'):\n",
    "    ds = DataSample(sample_file)\n",
    "    if ds.target == -1:\n",
    "        continue\n",
    "    if ds.metadata.mat == -1:\n",
    "        continue\n",
    "    data[ds.key].append(ds)\n",
    "    \n",
    "assert all([len(electrodes) == N_ELECTRODES for key, electrodes in data.items()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Represent CV characteristic fingerprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_data = [CompoundDataSample(samples) for samples in data.values()]\n",
    "n_compounds = len(compound_data)\n",
    "print(f'n = {n_compounds}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cds = CompoundDataSample(list(data.values())[0])\n",
    "nn = cds.to_nn_sample(mode=DataEncodeMode.SECOND_CYCLE_ONLY, onehot_target=False, vector=True)\n",
    "print(nn['cycles'].shape, nn['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_data[17].represent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compound_data = [CompoundDataSample(samples) for samples in data.values()]\n",
    "data_train, data_val = split_dataset(compound_data, 0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_val, y_val) = make_data(data_train, data_val,\n",
    "                                               batch_size=batch_size,\n",
    "                                               mode=DataEncodeMode.ALL_CYCLES,\n",
    "                                               augmentations=[], \n",
    "                                               vector=True,\n",
    "                                               onehot_target=False,\n",
    "                                               to_tf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_cl = xgb.XGBClassifier(objective=\"multi:softmax\", max_depth=20, n_estimators=100)\n",
    "xgb_cl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb_cl.predict(X_val)\n",
    "calc_metrics(preds, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train FCN on CVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!del FCN.weights.h5*\n",
    "all_cycles = Path('FCN.weights.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = DataEncodeMode.ALL_CYCLES #alternatively use FIRST_CYCLE_ONLY or SECOND_CYCLE_ONLY\n",
    "train_dataset, val_dataset = make_data(data_train, data_val,\n",
    "                                       batch_size=batch_size,\n",
    "                                       mode=mode,\n",
    "                                       augmentations=[aug], \n",
    "                                       vector=False,\n",
    "                                       onehot_target=True,\n",
    "                                       to_tf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCN_Model(mode=mode,\n",
    "                                   n_filters_sequence = (8, 16, 32),\n",
    "                                   kernel_size_sequence = (8, 4, 2),\n",
    "                                   pool_window_size_sequence = (4, 4, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = train(all_cycles, model, train_dataset, val_dataset, 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collect MS data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datadir = Path(\"MS\").glob('*.mzXML')\n",
    "ms_data: List[MSDataSample] = []\n",
    "for sample_file in train_datadir:\n",
    "    ds = MSDataSample(sample_file.as_posix())\n",
    "    ms_data.append(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ms_data[0].represent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_data_train, ms_data_val = split_dataset(ms_data, 0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(ms_data_train), len(ms_data_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train FCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode = DataEncodeMode.MS\n",
    "ms_train_dataset, ms_val_dataset = make_data(ms_data_train, ms_data_val,\n",
    "                                             batch_size=batch_size,\n",
    "                                             mode=mode,\n",
    "                                             augmentations=[], \n",
    "                                             vector=False,\n",
    "                                             onehot_target=True,\n",
    "                                             to_tf=True,\n",
    "                                             do_preprocess=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FCN_Model(mode=DataEncodeMode.MS, \n",
    "                                   n_filters_sequence=(8, 16, 32),\n",
    "                                   kernel_size_sequence=(4, 2, 3),\n",
    "                                   pool_window_size_sequence=(2, 2, 2),\n",
    "                                   input_sequence_length=N_PEAKS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms_path = Path('ms.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = train(ms_path, model, ms_train_dataset, ms_val_dataset, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(model, ms_val_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "etongue_environment",
   "language": "python",
   "name": "etongue_environment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
